{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Filters\n",
    "\n",
    "To filter signals on graphs, we need to define filters. They are represented in the toolbox by the [`pygsp.filters.Filter` class](https://pygsp.readthedocs.io/en/stable/reference/filters.html). Filters are usually defined in the spectral domain. Given the transfer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pygsp import graphs, filters, utils\n",
    "from additional_utils import get_approx_filter\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Heat diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The heat kernel $h(\\lambda)$ is defined as:\n",
    "$$h_\\tau(\\lambda)=\\exp^{-\\tau\\lambda}.$$\n",
    "In fact, the graph heat equation reads (see section 2.5.5. of *Discrete Calculus* (by Grady and Polimeni)):\n",
    "$$\\frac{d\\mathbf{x}}{dt}+\\mathbf{Lx} = \\mathbf{0}.$$\n",
    "In the Fourier space, this translates in:\n",
    "$$\\frac{d\\hat{\\mathbf{x}}}{dt}+\\mathbf{\\Lambda}\\hat{\\mathbf{x}} = \\mathbf{0},$$\n",
    "where $\\hat{\\mathbf{x}}=\\mathbf{U}^\\top\\mathbf{x}$ is the Fourier transform of $\\mathbf{x}$. This equation is easily solved in each dimension by the exponential with:\n",
    "$$\\hat{\\mathbf{x}} = \\exp^{-t\\mathbf{\\Lambda}}\\hat{\\mathbf{x}_0}$$\n",
    "where $\\hat{x_0}$ is the initial signal at time $t=0$. Such that:\n",
    "$$\\mathbf{x}(t) =\\mathbf{U} \\exp^{-t\\mathbf{\\Lambda}}\\mathbf{U}^\\top \\mathbf{x}_0=\\mathbf{U} h_t(\\mathbf{\\Lambda})\\mathbf{U}^\\top \\mathbf{x}_0.$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1 = graphs.Sensor(seed=42)\n",
    "G1.compute_fourier_basis()\n",
    "G2 = graphs.Ring(N=100)\n",
    "G2.compute_fourier_basis()\n",
    "G2.set_coordinates('line1D')\n",
    "\n",
    "TAUS = [0, 5, 100]\n",
    "DELTA = 10\n",
    "\n",
    "fig, axes = plt.subplots(len(TAUS), 3, figsize=(15, 6))\n",
    "\n",
    "for i, tau in enumerate(TAUS):\n",
    "    g1 = filters.Heat(G1, tau)\n",
    "    g2 = filters.Heat(G2, tau)\n",
    "    \n",
    "    y = g1.localize(DELTA).squeeze()\n",
    "    G1.plot_signal(y, ax=axes[i, 0])\n",
    "    axes[i, 0].set_axis_off()\n",
    "    axes[i, 0].text(0, -0.2, '$y^T L y = {:.2f}$'.format(y.T @ G1.L @ y))\n",
    "    \n",
    "    G2.plot_signal(g2.localize(G2.N//2), ax=axes[i, 2])\n",
    "    \n",
    "    g1.plot(ax=axes[i, 1])\n",
    "    axes[i, 1].set_xlabel('')\n",
    "    axes[i, 1].set_ylabel('')\n",
    "    text = r'$\\hat{{g}}(\\lambda) = \\exp \\left( \\frac{{-{{{}}} \\lambda}}{{\\lambda_{{max}}}} \\right)$'.format(tau)\n",
    "    axes[i, 1].text(6, 0.5, text, fontsize=15)\n",
    "    \n",
    "axes[0, 0].set_title('$y = \\hat{{g}}(L) \\delta_{{{}}}$: localized on sensor'.format(DELTA))\n",
    "axes[0, 1].set_title('$\\hat{g}(\\lambda)$: filter defined in the spectral domain')\n",
    "axes[0, 2].set_title('$y = \\hat{{g}}(L) \\delta_{{{}}}$: localized on ring graph'.format(G2.N//2))\n",
    "axes[-1, 1].set_xlabel(\"$\\lambda$: laplacian's eigenvalues / graph frequencies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Exercise\n",
    "\n",
    "Solve the following problem using a graph filter:\n",
    "$$\\mathbf{x}^* = \\operatorname*{arg\\,min}_{\\mathbf{x} \\in \\mathbb{R}^N} \\|\\mathbf{y} - \\mathbf{x}\\|_2^2 + \\alpha \\mathbf{x}^\\intercal \\mathbf{L} \\mathbf{x},$$\n",
    "where $y$ is the observed signal, $\\alpha$ is an hyper-parameter which controls the trade-off between the data fidelity term and the smoothness prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Example of denoising\n",
    "Let's define a low-pass filter\n",
    "$$g(\\lambda) = \\frac{1}{1+\\tau\\lambda}$$\n",
    "Given a noisy version of a smooth signal $x_\\text{noisy}$, one can denoise it with the low-pass filter $g$:\n",
    "$$ x_\\text{denoised} = \\mathbf{U}g(\\mathbf{\\Lambda})\\mathbf{U}^\\top x_{\\text{noisy}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the graph:\n",
    "G = graphs.Logo()\n",
    "G.compute_fourier_basis()\n",
    "\n",
    "# the filter:\n",
    "tau = 1\n",
    "def g(x):\n",
    "    return 1. / (1. + tau * x)\n",
    "g = filters.Filter(G, g)\n",
    "\n",
    "# the noisy signal:\n",
    "x = np.zeros(G.N)\n",
    "x[G.info['idx_g']-1] = -1\n",
    "x[G.info['idx_s']-1] = 0\n",
    "x[G.info['idx_p']-1] = 1\n",
    "rs = np.random.RandomState(42)\n",
    "x_noisy = x + rs.uniform(-1, 1, size=G.N)\n",
    "\n",
    "# the denoised signal:\n",
    "x_denoised = g.filter(x_noisy, method='exact')\n",
    "\n",
    "# and... plot:\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 3))\n",
    "G.plot_signal(x_noisy, vertex_size=30, ax=axes[0])\n",
    "_ = axes[0].set_title('Noisy signal')\n",
    "axes[0].set_axis_off()\n",
    "G.plot_signal(x_denoised, vertex_size=30, ax=axes[1])\n",
    "_ = axes[1].set_title('Cleaned signal')\n",
    "axes[1].set_axis_off()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Polynomial approximation\n",
    "Let us approximate the filter $$g(x) = \\frac{1}{1+x}$$ on the interval $[0,\\lambda_N]$ by a Chebychev polynomial of order $m$:\n",
    "$$g(x) \\simeq \\sum_{k=0}^m \\alpha_k x^k=p(x),$$\n",
    "such that the exact filtering can be approximated by a polynomial in $\\mathbf{L}$:\n",
    "\\begin{align}\n",
    "x_{\\text{filtered}}&=\\mathbf{U}g(\\mathbf{\\Lambda})\\mathbf{U}^\\top x\\\\\n",
    "&\\simeq \\mathbf{U}p(\\mathbf{\\Lambda})\\mathbf{U}^\\top x\\\\\n",
    "&=\\mathbf{U}\\sum_{k=0}^m \\alpha_k \\mathbf{\\Lambda}^k\\mathbf{U}^\\top x\\\\\n",
    "&=\\sum_{k=0}^m \\alpha_k \\mathbf{L}^k x\n",
    "\\end{align}\n",
    "Note that computing $\\sum_{k=0}^m \\alpha_k \\mathbf{L}^k x$ takes only $m$ matrix-vector multiplication and costs thus $\\mathcal{O}(m|E|)$ with $|E|$ the number of edges of the graph (compared to the $\\mathcal{O}(N^3)$ necessary operations just to diagonalize $\\mathbf{L}$ for the exact computation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = lambda x: 1 / (1 + x)\n",
    "filt_g = filters.Filter(G, g)\n",
    "c = filters.approximations.compute_cheby_coeff(filt_g, m=m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_approx = get_approx_filter(c)\n",
    "\n",
    "x = np.arange(0, G.lmax, (G.lmax) / 1000)\n",
    "plt.figure()\n",
    "plt.plot(x, g(x))\n",
    "plt.hold\n",
    "plt.plot(x, np.squeeze(filt_approx((x-(G.lmax/2)) / (G.lmax/2))))\n",
    "plt.legend(['original filter', 'polynomial approximation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "G.compute_fourier_basis(recompute = True) #just to measure time\n",
    "x_denoised_exact = filt_g.filter(x_noisy, method='exact')\n",
    "time_exact_filter = time.time() - start_time\n",
    "start_time = time.time()\n",
    "G.estimate_lmax(recompute = True) #just to measure time\n",
    "x_denoised_cheby = filt_g.filter(x_noisy, method='chebyshev', order=m)\n",
    "time_cheby_filter = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 3))\n",
    "G.plot_signal(x_denoised_exact, vertex_size=30, ax=axes[0])\n",
    "_ = axes[0].set_title('Exact denoising')\n",
    "axes[0].set_axis_off()\n",
    "G.plot_signal(x_denoised_cheby, vertex_size=30, ax=axes[1])\n",
    "_ = axes[1].set_title('Chebyshev approx')\n",
    "axes[1].set_axis_off()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The max error is ' + str(np.max(np.abs(x_denoised_exact-x_denoised_cheby))))\n",
    "print('The mean energy of the error is ' + str((np.sum((x_denoised_exact - x_denoised_cheby)**2)/G.N)))\n",
    "\n",
    "print('The computation time for exact filtering was ' + str(time_exact_filter))\n",
    "print('The computation time for approx filtering was ' + str(time_cheby_filter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Precision-Efficiency trade-off of the polynomial approximation\n",
    "Illustrate the precision vs computation time trade-off of the Chebyshev polynomial approximation, as the order of the polynomial changes. How about with the ideal low-pass```g = lambda x: x <= cut_off_freq```?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Spectral Graph Wavelets\n",
    "Given a (smooth-enough) bandpass filter $g(u)$, a wavelet centered on node $i$ at scale $s\\geq0$ reads:\n",
    "$$\\mathbf{\\psi}_{s,i} = \\mathbf{U}g(s\\mathbf{\\Lambda})\\mathbf{U}^\\top \\mathbf{\\delta}_i\\in\\mathbb{R}^{N},$$ \n",
    "where $\\mathbf{\\delta}_i\\in\\mathbb{R}^N$ is the Dirac centered on node $i$: $\\mathbf{\\delta}_i(i)=1$ and $0$ elsewhere. See the [seminal paper](https://hal.inria.fr/file/index/docid/541855/filename/hammond-vandergheynst-gribonval-acha-2009r.pdf) by Hammond et al. for details on spectral graph wavelets. Given a graph signal $\\mathbf{x}$, the wavelet coefficient at node $i$ and scale $s$, denoted by $W_{s,i}(\\mathbf{x})$, is the projection of the signal on $\\mathbf{\\psi}_{s,i}$:\n",
    "$$W_{s,i}(\\mathbf{x}) = \\mathbf{\\psi}_{s,i}^\\top\\mathbf{x}\\in\\mathbb{R}.$$\n",
    "\n",
    "Let us consider $\\mathcal{S}=(s_1, s_2, \\ldots, s_m)$ a set of $m$ scales. The collection of $m$ filters $\\{g(s_1 u), g(s_2 u), \\ldots, g(s_m u)\\}$ is called a *filterbank*. Consider all wavelet coefficients $\\{W_{s,i}\\}_{s\\in\\mathcal{S},~i\\in\\mathcal{V}}$ of a graph signal $\\mathbf{x}$. Can we recover perfectly $\\mathbf{x}$ from its wavelet coefficients? The answer is \"no\" because wavelet filters are necessarily bandpass (thus $g(0)=0$) and constant signals are in the null space of the transform!\n",
    "\n",
    "Let us add a low-pass $h(u)$ to the filterbank for instance (the exact form does not have a huge importance):\n",
    "$$h(u)=\\exp^{-u^4}.$$\n",
    "\n",
    "Do the coefficients extracted from the combination of filters $(h(u), g(s_1 u), g(s_2 u), \\ldots, g(s_m u))$ enough for perfect reconstruction of any $\\mathbb{R}^N$ signal?\n",
    "\n",
    "**Theorem.** (see Theorem 5.6 of [Hammond et al.](https://hal.inria.fr/file/index/docid/541855/filename/hammond-vandergheynst-gribonval-acha-2009r.pdf)) Perfect recovery is possible iff \n",
    "$$\\text{min}_{u\\in\\{\\lambda_0, \\ldots, \\lambda_{N-1}\\}} \\quad h(u)^2 + \\sum_{s\\in\\mathcal{S}} g(su)^2 > 0.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = graphs.Sensor(seed=42)\n",
    "G.compute_fourier_basis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mexican hat bandpass example\n",
    "mex_hat = lambda x: x * np.exp(-x) \n",
    "plt.plot(np.arange(0,10,0.01), mex_hat(np.arange(0,10,0.01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=5\n",
    "g = filters.MexicanHat(G, Nf = m + 1, lpfactor = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_x = np.arange(0, G.lmax, G.lmax/1000)\n",
    "y = g.evaluate(eval_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(eval_x, y.T)\n",
    "plt.plot(G.e, g.evaluate(G.e).T, '+')\n",
    "plt.xlabel('$\\lambda$')\n",
    "plt.ylabel('filters')\n",
    "plt.figure()\n",
    "plt.plot(G.e, np.sum(np.power(g.evaluate(G.e).T,2),1), '+')\n",
    "plt.ylim([0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see on the last graph, we have :\n",
    "$$\\text{min}_{u\\in\\{\\lambda_0, \\ldots, \\lambda_{N-1}\\}} \\quad h(u)^2 + \\sum_{s\\in\\mathcal{S}} g(su)^2 > 0.$$\n",
    "Perfect reconstruction of all $\\mathbb{R}^N$ signals is thus possible! The frame is not tight though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot a few wavelets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node = 10\n",
    "delta_node = np.zeros((G.N,))\n",
    "delta_node[node] = 1\n",
    "wavelet_at_node = g.filter(delta_node)\n",
    "wavelet_at_node.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.plot_signal(delta_node) # the delta signal centered on 'node'\n",
    "G.plot_signal(wavelet_at_node[:,5]) # the wavelet centered on 'node' at very small scale (large value of s)\n",
    "G.plot_signal(wavelet_at_node[:,4]) # the wavelet at the same node but at slightly larger scale (smaller value of s)\n",
    "G.plot_signal(wavelet_at_node[:,3]) # etc.\n",
    "G.plot_signal(wavelet_at_node[:,2])\n",
    "G.plot_signal(wavelet_at_node[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example** Plot some wavelets in the SBM model. Observe how wavelets first \"diffuse\" within the blocks before exploring the whole network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filterbanks for compression :**\n",
    "We are going to use the filterbanks 'Itersine' (which forms a tight frame). Some methods exist to 'tighten' the frame formed by the 'MexicanHat' for instance, but we will not look into this here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=5\n",
    "g = filters.Itersine(G, Nf = m + 1)\n",
    "eval_x = np.arange(0, G.lmax, G.lmax/1000)\n",
    "y = g.evaluate(eval_x)\n",
    "plt.plot(eval_x, y.T)\n",
    "plt.plot(G.e, g.evaluate(G.e).T, '+')\n",
    "plt.xlabel('$\\lambda$')\n",
    "plt.ylabel('filters')\n",
    "plt.figure()\n",
    "plt.plot(G.e, np.sum(np.power(g.evaluate(G.e).T,2),1), '+')\n",
    "plt.ylim([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_level = 0.9 #a scalar between 0 and 1, 0 meaning no compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_toy_orig = - np.ones((G.N,))\n",
    "ind_left = G.coords[:,0] < 0.5\n",
    "x_toy_orig[ind_left] = 1\n",
    "x_toy_noisy = x_toy_orig + 0.2 * np.random.randn(G.N)\n",
    "G.plot_signal(x_toy_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_coeffs = g.filter(x_toy_noisy, method='exact')\n",
    "n_coef = np.prod(W_coeffs.shape) # total number of scalars encoding the signal in the wavelet space\n",
    "n_coef_comp = np.ceil((1 - comp_level) * n_coef).astype(int) # authorized number of scalars at specified compression level\n",
    " # find the threshold under which we will set entries to 0:\n",
    "sorted_coefs = np.sort(np.abs(W_coeffs), axis=None) \n",
    "threshold = sorted_coefs[-n_coef_comp]\n",
    " # the thresholded wavelet transform:\n",
    "W_coeffs_th = W_coeffs.copy()\n",
    "W_coeffs_th[np.abs(W_coeffs) < threshold] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_toy_recovered = g.synthesize(W_coeffs_th, method='exact')\n",
    "G.plot_signal(x_toy_recovered)\n",
    "print(str(np.linalg.norm(x_toy_recovered-x_toy_noisy)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** Plot the error of reconstruction vs the compression rate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is only one quick example of compression. Denoising may be done as well, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
